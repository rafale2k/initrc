#!/bin/bash
# --- Gemini AI Assistant: ask, wtf, dask & dinv (llm powered v3.0) ---

# [æœ¬ç•ªç´šè¨­å®š] ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’ä¸€æ‹¬ç®¡ç†
# ç¾æ™‚ç‚¹ã§æœ€ã‚‚é«˜æ€§èƒ½ãª preview ãƒ¢ãƒ‡ãƒ«ã‚’æŒ‡å®šã€‚å®‰å®šç‰ˆãŒè‰¯ã‘ã‚Œã° gemini-2.5-flash ã«å¤‰æ›´ã—ã¦ãã ã•ã„
export AI_ASSIST_MODEL="gemini/gemini-3-flash-preview"

# [å†…éƒ¨ç”¨] å®Ÿè¡Œä¸­ã®ã‚³ãƒ³ãƒ†ãƒŠã‚’ fzf ã§é¸ã‚“ã§åå‰ã‚’è¿”ã™é–¢æ•°
_select_container() {
    # å®Ÿè¡Œä¸­ã®ã‚³ãƒ³ãƒ†ãƒŠä¸€è¦§ã‚’å–å¾—ã—ã€å³å´ã«ãƒ­ã‚°ã‚’è¡¨ç¤ºã™ã‚‹ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼æ©Ÿèƒ½ä»˜ã
    docker ps --format "table {{.Names}}\t{{.Status}}\t{{.Image}}" | \
        sed '1d' | \
        fzf --height 40% --layout=reverse --border \
            --header "Select a container to inspect (Preview shows last 20 lines of logs)" \
            --preview "docker logs --tail 20 {1} 2>&1" | \
        awk '{print $1}'
}

# [æ±ç”¨] è³ªå•ã‹ã‚‰ã‚³ãƒãƒ³ãƒ‰ã‚’ç”Ÿæˆãƒ»å®Ÿè¡Œ
ask() {
    local query="$*"
    [[ -z "$query" ]] && { echo "ğŸ¤” Usage: ask 'Your question'"; return 1; }

    local system_prompt="You are a CLI expert. Output ONLY a valid shell command. No markdown, no backticks."
    echo "ğŸ¤– Thinking..."
    
    local raw_cmd
    raw_cmd=$(llm -m "$AI_ASSIST_MODEL" -s "$system_prompt" "$query")
    # ä¸è¦ãªãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã‚’å–ã‚Šé™¤ãã€ã‚¯ãƒªãƒ¼ãƒ³ãªã‚³ãƒãƒ³ãƒ‰ã‚’æŠ½å‡º
    local cmd
    cmd=$(echo "$raw_cmd" | sed -e 's/```[a-z]*//g' -e 's/```//g' | tr -d '`' | xargs)

    [[ -z "$cmd" ]] && { echo "âŒ Failed to generate command."; return 1; }

    echo -e "\nğŸ‘‰ AI suggests:\n\033[1;32m$cmd\033[0m\n"
    echo -n "Run this command? [y/N]: "
    local answer
    read -r answer < /dev/tty

    if [[ "$answer" =~ ^[Yy]$ ]]; then
        echo "ğŸš€ Executing..."
        ( eval "$cmd" )
    else
        echo "Aborted."
    fi
}

# [Dockerç‰¹åŒ–] ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’èª­ã¿å–ã£ã¦æ“ä½œã‚’ææ¡ˆ
dask() {
    local query="$*"
    [[ -z "$query" ]] && { echo "ğŸ¤” Usage: dask 'Docker task'"; return 1; }

    echo "ğŸ³ Analyzing Docker context..."

    # è³¢ã•ã‚’æœ€å¤§åŒ–ã™ã‚‹ãŸã‚ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåé›†
    local context="[Context]\n"
    [[ -f "docker-compose.yml" ]] && context+="Compose File (head):\n$(head -n 50 docker-compose.yml)\n\n"
    context+="Container Status:\n$(docker ps --format '{{.Names}} ({{.Status}})')\n"
    # ç›´è¿‘ã®ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’å«ã‚ã‚‹ã“ã¨ã§ã€ãƒˆãƒ©ãƒ–ãƒ«è§£æ±ºã®ç²¾åº¦ã‚’åŠ‡çš„ã«ä¸Šã’ã‚‹
    context+="Recent Logs excerpt:\n$(docker compose logs --tail 15 2>/dev/null)\n"

    local system_prompt="You are a Docker/DevOps expert. 
    1. Output a brief explanation (1 line) about why this command is suggested.
    2. Output the command in a NEW line.
    3. Use NO markdown formatting."

    local response
    response=$(echo -e "$context" | llm -m "$AI_ASSIST_MODEL" -s "$system_prompt" "$query")

    # 1è¡Œç›®ã®è§£èª¬ã¨2è¡Œç›®ä»¥é™ã®ã‚³ãƒãƒ³ãƒ‰ã‚’åˆ†é›¢
    local explanation=$(echo "$response" | head -n 1)
    local cmd=$(echo "$response" | tail -n +2 | xargs)

    [[ -z "$cmd" ]] && { echo "âŒ Failed to generate command."; return 1; }

    echo -e "\nğŸ’¡ \033[1;34m$explanation\033[0m"
    echo -e "ğŸ‘‰ AI suggests: \033[1;32m$cmd\033[0m\n"
    
    echo -n "Run? [y/N]: "
    local answer
    read -r answer < /dev/tty
    if [[ "$answer" =~ ^[Yy]$ ]]; then
        echo "ğŸš€ Executing..."
        ( /bin/bash -c "$cmd" )
    fi
}

# [è§£æ] ãƒ­ã‚°ã‚„ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è§£æ±ºç­–ã‚’æç¤º
wtf() {
    local context=$( [[ -n "$1" ]] && echo "$1" || { clipcopy --paste 2>/dev/null || pbpaste 2>/dev/null; } )
    [[ -z "$context" ]] && { echo "âš ï¸ No error context found in arguments or clipboard."; return 1; }

    echo "ğŸ” Analyzing error..."
    local system_prompt="You are a senior DevOps engineer. Analyze this error and provide a concise fix."
    
    echo -e "--- ğŸ¤– Error Analysis ---\n"
    # glow ãŒã‚ã‚Œã°ç¶ºéº—ã«è¡¨ç¤º
    if command -v glow > /dev/null; then
        echo "$context" | llm -m "$AI_ASSIST_MODEL" -s "$system_prompt" | glow
    else
        echo "$context" | llm -m "$AI_ASSIST_MODEL" -s "$system_prompt"
    fi
    echo -e "\n--------------------------"
}

# [èª¿æŸ»] ã‚³ãƒ³ãƒ†ãƒŠå†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ SRE è¦–ç‚¹ã§ç²¾å¯†è¨ºæ–­
dinv() {
    local container=$1
    local file_path=$2
    local query=${3:-"Analyze this file for any misconfigurations, security risks, or performance issues. Provide a 'Summary' and 'Action Plan'."}

    # ã‚³ãƒ³ãƒ†ãƒŠåãŒãªã‘ã‚Œã° fzf ã§é¸æŠ
    if [[ -z "$container" ]]; then
        container=$(_select_container)
        [[ -z "$container" ]] && return 1
        echo "âœ… Selected: $container"
    fi

    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ãŒãªã‘ã‚Œã°å…¥åŠ›ã‚’ä¿ƒã™
    if [[ -z "$file_path" ]]; then
        echo -n "Enter file path to inspect (e.g. /etc/mysql/my.cnf): "
        read -r file_path < /dev/tty
        [[ -z "$file_path" ]] && return 1
    fi

    echo "ğŸ” Reading $file_path from $container..."
    local content
    content=$(docker exec "$container" cat "$file_path" 2>/dev/null)
    
    if [[ -z "$content" ]]; then
        echo "âŒ File not found or empty."
        return 1
    fi

    local system_prompt="You are a Senior SRE specialist. Address the query based on the file content provided."
    
    echo -e "ğŸ¤– Analyzing with Gemini...\n"
    if command -v glow > /dev/null; then
        echo -e "[File: $file_path]\n$content" | llm -m "$AI_ASSIST_MODEL" -s "$system_prompt" "$query" | glow
    else
        echo -e "[File: $file_path]\n$content" | llm -m "$AI_ASSIST_MODEL" -s "$system_prompt" "$query"
    fi
}
